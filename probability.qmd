# Probability

{{< include macros.qmd >}}

## Random variables

### Types of random variables

:::{#def-binary}

#### binary variable
A **binary variable** is a random variable which has only two possible values in its range.

:::

{{< include binary-outcome-examples.qmd >}}


## Key probability distributions

:::::{#def-bernoulli}
#### Bernoulli distribution
The **Bernoulli distribution** family for a random variable $X$ is defined as:

$$
\ba
\Pr(X=x) &= \1{x\in \set{0,1}}\pi^x(1-\pi)^{1-x}\\
&= \cbl{{\pi, x=1}\atop{1-\pi, x=0}}
\ea
$$

:::::


## Characteristics of probability distributions

:::{#def-density}
### Density function

The density function $f(t)$ for a random variable $T$ at value $t$ can be defined as the derivative of the cumulative probability function $P(T\le t)$; that is:

$$f(t) \eqdef \frac{d}{dt} \Pr(T\le t)$$

:::

:::{#def-hazard}

{{< include _def-hazard.qmd >}}

:::

:::{#def-expectation}
### Expectation, expected value \index{expectation} \index{expected value}

The *expectation* or *expected value* of a random variable $X$, denoted $\E{X}$, $\mu(X)$, or $\mu_X$, is its mean:

$$\E{X} = \int_{x\in \range{X}} x \cdot p(X=x)dx$$

(c.f. https://en.wikipedia.org/wiki/Expected_value)

:::

:::{#def-variance}
### Variance

The variance of a random variable $X$ is the expectation of the squared difference between $X$ and $\E{X}$; that is:

$$
\Var{X} \eqdef \E{(X-\E{X})^2}
$$

:::

:::{#thm-variance}
### Alternative expression for variance

$$\Var{X}=\E{X^2} - \sqf{\E{X}}$$

::::{.proof}
By linearity of expectation, we have:

$$
\begin{aligned}
\Var{X} 
&\eqdef \E{(X-\E{X})^2}\\
&=\E{X^2 - 2X\E{X} + \sqf{\E{X}}}\\
&=\E{X^2} - \E{2X\E{X}} + \E{\sqf{\E{X}}}\\
&=\E{X^2} - 2\E{X}\E{X} + \sqf{\E{X}}\\
&=\E{X^2} - \sqf{\E{X}}\\
\end{aligned}
$$
::::

:::


::: {#def-precision}
### Precision

The **precision** of a random variable $X$, often denoted $\tau(X)$, $\tau_X$, or shorthanded as $\tau$, is
the inverse of that random variable's variance; that is:

$$\tau(X) \eqdef \inv{\Var{X}}$$
:::

::: {#def-sd}

### Standard deviation

The standard deviation of a random variable $X$ is the square-root of the variance of $X$:

$$\SD{X} \eqdef \sqrt{\Var{X}}$$

:::

:::{#def-cov}
### Covariance

For any two one-dimensional random variables, $X,Y$:

$$\Cov{X,Y} \eqdef \Expf{(X - EX)(Y - EY)}$$

:::

:::{#thm-alt-cov}
$${Cov}(X,Y)= E[XY] - E[X] E[Y]$$
:::


:::{.proof}
Left to the reader.
:::

:::{#lem-cov-xx}
$$\Cov{X,X} = \Var{X}$$
:::

:::{.proof}
$$
\ba
\Cov{X,X} &= E[XX] - E[X]E[X] 
\\ &= E[X^2]-(E[X])^2
\\ &= \Var{X}
\ea
$$
:::

:::{#def-cov-vec-x}

### Variance/covariance of a $p \times 1$ random vector

For a $p \times 1$ dimensional random vector $X$,

$$
\begin{aligned}
\text{Var}(X) 
&\eqdef \text{Cov}(X)\\
&\eqdef E[ \left( X - E\lbrack X\rbrack \right)^{\top}\left( X - E\lbrack X\rbrack \right) ]\\
\ea
$$

:::

:::{#thm-vcov-vec}

### Alternate expression for variance of a random vector
$$
\ba
\Var{X} 
&= E[ X^{\top}X ] - {E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack
\end{aligned}
$$
:::

:::{.proof}
$$
\ba
\Var{X} 
&= E[ \left( X^{\top} - E\lbrack X\rbrack^{\top} \right)\left( X - E\lbrack X\rbrack \right) ]\\
&= E[ X^{\top}X - E\lbrack X\rbrack^{\top}X - X^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack ]\\
&= E[ X^{\top}X ] - E\lbrack X\rbrack^{\top}E\lbrack X\rbrack - {E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack\\
&= E[ X^{\top}X ] - 2{E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack + E\lbrack X\rbrack^{\top}E\lbrack X\rbrack\\
&= E[ X^{\top}X ] - {E\lbrack X\rbrack}^{\top}E\lbrack X\rbrack
\end{aligned}
$$
:::

:::{#def-indpt}

#### Statistical independence

A set of random variables $\X1n$ are **statistically independent** if their joint probability is equal to the product of their marginal probabilities:

$$\Pr(\Xx1n) = \prodi1n{\Pr(X_i=x_i)}$$

:::


:::{#def-homosked}
#### homoskedastic
A random variable $Y$ is **homoskedastic** (with respect to covariates $X$) if the variance of $Y$ does not vary with $X$: 

$$\Varr(Y|X=x) = \ss, \forall x$$

Otherwise it is **heteroskedastic**.
:::
